{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f26811",
   "metadata": {},
   "source": [
    "# Project, Part 1, Attempt 1\n",
    "# Rohan Krishnamurthi\n",
    "# 9/5/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ee97d",
   "metadata": {},
   "source": [
    "# 0: initial preparation of folders, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce2228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import pybedtools\n",
    "import os\n",
    "from pybedtools import BedTool\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa4fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1eca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += ':/opt/homebrew/bin/bedtools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f9af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin:/opt/homebrew/sbin:/Users/rohankrishnamurthi/anaconda3/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/TeX/texbin:/Applications/quarto/bin:/opt/homebrew/bin/bedtools\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13b24827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd(\"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ac113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file with region of 10,000 BP from transcription start site\n",
    "kBP_10_df = pd.read_table('TF_TSS_10kb_named.bed', header = None)\n",
    "kBP_10_df[4] = (kBP_10_df[1] + kBP_10_df[2])/2\n",
    "\n",
    "# Convert data frame to bedtool\n",
    "kBP_10_updated = BedTool.from_dataframe(kBP_10_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdde8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set list of cell lines and histone marks\n",
    "lines = [\"A549\", \"H1\", \"HepG2\", \"K562\", \"GM12878\", \"MCF-7\"]\n",
    "marks = [\"H3K4me3\", \"H3K27Ac\", \"H3K9me3\", \"H3K27me3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f65e848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of folders (for loop 1)\n",
    "folders = []\n",
    "for i in lines:\n",
    "        for j in marks:\n",
    "                folder = f\"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/{i}/{j}\"\n",
    "                folders.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d906ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1417d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get list of files from a folder\n",
    "def list_files(folder):\n",
    "    files = []\n",
    "    for entry in os.listdir(folder):\n",
    "        if os.path.isfile(os.path.join(folder, entry)):\n",
    "            files.append(entry)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddad1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary of folder and relevant files (for loop 2)\n",
    "dictionary = {}\n",
    "for i in lines:\n",
    "        for j in marks:\n",
    "                folder = f\"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/{i}/{j}/\"\n",
    "                files = [file for file in list_files(folder) if (file != \".DS_Store\" and file != \".bed\") ]\n",
    "                dictionary[folder] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ebe429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K4me3/': ['ENCFF001WUM.bed.gz',\n",
       "  'ENCFF001WUL.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K27Ac/': [],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K9me3/': ['ENCFF407FDL.bed.gz',\n",
       "  'ENCFF155GOT.bed.gz',\n",
       "  'ENCFF911EGN.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K27me3/': [],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K4me3/': ['ENCFF001SVC.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K27Ac/': ['ENCFF001SUX.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K9me3/': ['ENCFF001SUW.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K27me3/': ['ENCFF001SUY.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K4me3/': ['ENCFF001XDC.bed.gz',\n",
       "  'ENCFF001XDB.bed.gz',\n",
       "  'ENCFF001SWO.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K27Ac/': ['ENCFF001SWK.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K9me3/': ['ENCFF001SWJ.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K27me3/': ['ENCFF001SWL.bed.gz',\n",
       "  'ENCFF001XCT.bed.gz',\n",
       "  'ENCFF001XCW.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K4me3/': ['ENCFF001XGU.bed.gz',\n",
       "  'ENCFF001SZJ.bed.gz',\n",
       "  'ENCFF001XGT.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K27Ac/': ['ENCFF001SZE.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K9me3/': ['ENCFF001SZN.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K27me3/': ['ENCFF001SZF.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K4me3/': ['ENCFF001WYJ.bed.gz',\n",
       "  'ENCFF001SUF.bed.gz',\n",
       "  'ENCFF001WYK.bed.gz',\n",
       "  'ENCFF001SUM.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K27Ac/': ['ENCFF001SUG.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K9me3/': ['ENCFF001SUP.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K27me3/': ['ENCFF001WYB.bed.gz',\n",
       "  'ENCFF001SUI.bed.gz',\n",
       "  'ENCFF001WYE.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/MCF-7/H3K4me3/': ['ENCFF001XHD.bed.gz',\n",
       "  'ENCFF001XHB.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/MCF-7/H3K27Ac/': [],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/MCF-7/H3K9me3/': [],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/MCF-7/H3K27me3/': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8511232",
   "metadata": {},
   "source": [
    "# 1: Histone Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de1c2f",
   "metadata": {},
   "source": [
    "## 1a: individual histone marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8614ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/mp8rwqxx7kj78jky4wxl4x_m0000gn/T/ipykernel_96977/1318227349.py:41: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
      "/var/folders/p9/mp8rwqxx7kj78jky4wxl4x_m0000gn/T/ipykernel_96977/1318227349.py:41: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(bed_path, sep='\\t', header=None)\n"
     ]
    }
   ],
   "source": [
    "x = pybedtools.BedTool()\n",
    "word_to_remove = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/\"\n",
    "save_folder = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_processed_data\"\n",
    "\n",
    "for folder in dictionary:\n",
    "        name = folder\n",
    "        name_abb = ((folder.replace(word_to_remove, \"\")).replace(\"/\",\"_\"))[:-1]\n",
    "        files = dictionary[folder]\n",
    "        \n",
    "        if len(files) >= 1:\n",
    "            bed_path = f'{save_folder}/{name_abb}.bed.gz'\n",
    "            csv_path = f'{save_folder}/{name_abb}_consensus_all.csv'\n",
    "            bed_path_2 = f'{save_folder}/{name_abb}_consensus_all.bed'\n",
    "        \n",
    "            intersection_list =[]\n",
    "            \n",
    "            for file in files: \n",
    "                intersection_list.append(BedTool(name + file).fn)\n",
    "            \n",
    "            intersection_list.append(kBP_10_updated.fn)\n",
    "            \n",
    "            result = x.multi_intersect(i=intersection_list)\n",
    "            result.saveas(bed_path)\n",
    "            \n",
    "            len_files = len(files)\n",
    "            n = len_files+5\n",
    "            column_mapping = {\n",
    "                0: 'chrom',\n",
    "                1: 'start',\n",
    "                2: 'end',\n",
    "                3: \"peak_count\",\n",
    "                4: \"files\",\n",
    "                n: \"TF_TSS_10kb_named.bed\"\n",
    "            }\n",
    "\n",
    "            for i in range(0, len_files):\n",
    "                file = files[i]\n",
    "                column_mapping[i+5] = f\"{file}\"\n",
    "\n",
    "\n",
    "            df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
    "            df = df.rename(columns=column_mapping)\n",
    "            \n",
    "            # Ensure peaks are found in all replicate experiments\n",
    "            df_filtered = df[df[\"peak_count\"] == max(df[\"peak_count\"])]\n",
    "            \n",
    "            #df_filtered.to_csv(csv_path, index = False)\n",
    "            df_filtered.to_csv(bed_path_2, sep='\\t', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07869534",
   "metadata": {},
   "source": [
    "## 1b: bivalency, H3K4me3 + H3K27me3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e54df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A549: none\n",
    "# H1: 2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2727e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dictionary.keys())\n",
    "values = list(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3006f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_updated = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        keys_updated.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e20105bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_A549 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"A549\" in key:\n",
    "            keys_A549.append(key)\n",
    "\n",
    "keys_H1 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"H1\" in key:\n",
    "            keys_H1.append(key)\n",
    "            \n",
    "keys_HepG2 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"HepG2\" in key:\n",
    "            keys_HepG2.append(key)\n",
    "            \n",
    "keys_K562 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"K562\" in key:\n",
    "            keys_K562.append(key)\n",
    "            \n",
    "keys_GM1287 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"GM1287\" in key:\n",
    "            keys_GM1287.append(key)\n",
    "            \n",
    "keys_MCF_7 = []\n",
    "for key in keys:\n",
    "    if (\"H3K4me3\" in key or \"H3K27me3\" in key):\n",
    "        if \"MCF-7\" in key:\n",
    "            keys_MCF_7.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a0de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_A549 = {k: dictionary[k] for k in keys_A549}\n",
    "dict_H1 = {k: dictionary[k] for k in keys_H1}\n",
    "dict_HepG2 = {k: dictionary[k] for k in keys_HepG2}\n",
    "dict_K562 = {k: dictionary[k] for k in keys_K562}\n",
    "dict_GM1287 = {k: dictionary[k] for k in keys_GM1287}\n",
    "dict_MCF_7 = {k: dictionary[k] for k in keys_MCF_7}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efc7da86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K4me3/': ['ENCFF001WUM.bed.gz',\n",
       "  'ENCFF001WUL.bed.gz'],\n",
       " '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/A549/H3K27me3/': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict_A549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "844f200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A549: no files\n",
    "\n",
    "#H1: one file, one file\n",
    "\n",
    "#HepG2: three files, three files    \n",
    "    \n",
    "#K562: three files, one file\n",
    "\n",
    "#GM1287: 4, 3\n",
    "\n",
    "#MCF-7: two files, no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75893e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pwd('/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c3c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H1: one file, one file\n",
    "x = pybedtools.BedTool()\n",
    "word_to_remove = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/\"\n",
    "save_folder = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_processed_data\"\n",
    "\n",
    "H1_list = ['/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K4me3/ENCFF001SVC.bed.gz', \n",
    "           '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/H1/H3K27me3/ENCFF001SUY.bed.gz']\n",
    "\n",
    "H1_list_short = ['H1/H3K4me3/ENCFF001SVC.bed.gz', 'H1/H3K27me3/ENCFF001SUY.bed.gz']\n",
    "\n",
    "bed_path = f'{save_folder}/H1_bivalency.bed.gz'\n",
    "csv_path = f'{save_folder}/H1_bivalency_consensus_all.csv'\n",
    "bed_path_2 = f'{save_folder}/H1_bivalency_consensus_all.bed'\n",
    "\n",
    "intersection_list = []\n",
    "for file in H1_list:\n",
    "    intersection_list.append(BedTool(file).fn)\n",
    "intersection_list.append(kBP_10_updated.fn)  \n",
    "    \n",
    "result = x.multi_intersect(i=intersection_list)\n",
    "result.saveas(bed_path)\n",
    "\n",
    "len_files = len(H1_list_short)\n",
    "n = len_files+5\n",
    "column_mapping = {\n",
    "    0: 'chrom',\n",
    "    1: 'start',\n",
    "    2: 'end',\n",
    "    3: \"peak_count\",\n",
    "    4: \"files\",\n",
    "    n: \"TF_TSS_10kb_named.bed\"\n",
    "}\n",
    "\n",
    "for i in range(0, len_files):\n",
    "    file = H1_list_short[i]\n",
    "    column_mapping[i+5] = f\"{file}\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Ensure peaks are found in all replicate experiments\n",
    "df_filtered = df[df[\"peak_count\"] == max(df[\"peak_count\"])]\n",
    "\n",
    "df_filtered.to_csv(csv_path, index = False)\n",
    "df_filtered.to_csv(bed_path_2, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c3afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HepG2: three files, three files\n",
    "x = pybedtools.BedTool()\n",
    "word_to_remove = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/\"\n",
    "save_folder = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_processed_data\"\n",
    "\n",
    "HepG2_list = ['/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K4me3/ENCFF001XDC.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K4me3/ENCFF001XDB.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K4me3/ENCFF001SWO.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K27me3/ENCFF001SWL.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K27me3/ENCFF001XCT.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/HepG2/H3K27me3/ENCFF001XCW.bed.gz',]\n",
    "\n",
    "HepG2_list_short = ['HepG2/H3K4me3/ENCFF001XDC.bed.gz',\n",
    "              'HepG2/H3K4me3/ENCFF001XDB.bed.gz',\n",
    "              'HepG2/H3K4me3/ENCFF001SWO.bed.gz',\n",
    "              'HepG2/H3K27me3/ENCFF001SWL.bed.gz',\n",
    "              'HepG2/H3K27me3/ENCFF001XCT.bed.gz',\n",
    "              'HepG2/H3K27me3/ENCFF001XCW.bed.gz',]\n",
    "\n",
    "bed_path = f'{save_folder}/HepG2_bivalency.bed.gz'\n",
    "csv_path = f'{save_folder}/HepG2_bivalency_consensus_all.csv'\n",
    "bed_path_2 = f'{save_folder}/HepG2_bivalency_consensus_all.bed'\n",
    "\n",
    "intersection_list = []\n",
    "for file in HepG2_list:\n",
    "    intersection_list.append(BedTool(file).fn)\n",
    "intersection_list.append(kBP_10_updated.fn)  \n",
    "    \n",
    "result = x.multi_intersect(i=intersection_list)\n",
    "result.saveas(bed_path)\n",
    "\n",
    "len_files = len(HepG2_list_short)\n",
    "n = len_files+5\n",
    "column_mapping = {\n",
    "    0: 'chrom',\n",
    "    1: 'start',\n",
    "    2: 'end',\n",
    "    3: \"peak_count\",\n",
    "    4: \"files\",\n",
    "    n: \"TF_TSS_10kb_named.bed\"\n",
    "}\n",
    "\n",
    "for i in range(0, len_files):\n",
    "    file = HepG2_list_short[i]\n",
    "    column_mapping[i+5] = f\"{file}\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Ensure peaks are found in all replicate experiments\n",
    "df_filtered = df[df[\"peak_count\"] == max(df[\"peak_count\"])]\n",
    "\n",
    "df_filtered.to_csv(csv_path, index = False)\n",
    "df_filtered.to_csv(bed_path_2, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5873c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K562: three files, one file\n",
    "x = pybedtools.BedTool()\n",
    "word_to_remove = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/\"\n",
    "save_folder = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_processed_data\"\n",
    "\n",
    "K562_list = ['/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K4me3/ENCFF001XGU.bed.gz',\n",
    "             '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K4me3/ENCFF001SZJ.bed.gz',\n",
    "             '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K4me3/ENCFF001XGT.bed.gz',\n",
    "             '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/K562/H3K27me3/ENCFF001SZF.bed.gz']\n",
    "\n",
    "K562_list_short = ['K562/H3K4me3/ENCFF001XGU.bed.gz',\n",
    "             'K562/H3K4me3/ENCFF001SZJ.bed.gz',\n",
    "             'K562/H3K4me3/ENCFF001XGT.bed.gz',\n",
    "             'K562/H3K27me3/ENCFF001SZF.bed.gz']\n",
    "\n",
    "bed_path = f'{save_folder}/K562_bivalency.bed.gz'\n",
    "csv_path = f'{save_folder}/K562_bivalency_consensus_all.csv'\n",
    "bed_path_2 = f'{save_folder}/K562_bivalency_consensus_all.bed'\n",
    "\n",
    "intersection_list = []\n",
    "for file in K562_list:\n",
    "    intersection_list.append(BedTool(file).fn)\n",
    "intersection_list.append(kBP_10_updated.fn)  \n",
    "    \n",
    "result = x.multi_intersect(i=intersection_list)\n",
    "result.saveas(bed_path)\n",
    "\n",
    "len_files = len(K562_list_short)\n",
    "n = len_files+5\n",
    "column_mapping = {\n",
    "    0: 'chrom',\n",
    "    1: 'start',\n",
    "    2: 'end',\n",
    "    3: \"peak_count\",\n",
    "    4: \"files\",\n",
    "    n: \"TF_TSS_10kb_named.bed\"\n",
    "}\n",
    "\n",
    "for i in range(0, len_files):\n",
    "    file = K562_list_short[i]\n",
    "    column_mapping[i+5] = f\"{file}\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Ensure peaks are found in all replicate experiments\n",
    "df_filtered = df[df[\"peak_count\"] == max(df[\"peak_count\"])]\n",
    "\n",
    "df_filtered.to_csv(csv_path, index = False)\n",
    "\n",
    "df_filtered.to_csv(bed_path_2, sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3db2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GM1287: 4, 3\n",
    "x = pybedtools.BedTool()\n",
    "word_to_remove = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/\"\n",
    "save_folder = \"/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_processed_data\"\n",
    "\n",
    "GM1287_list = ['/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K4me3/ENCFF001WYJ.bed.gz',\n",
    "               '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K4me3/ENCFF001SUF.bed.gz',\n",
    "               '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K4me3/ENCFF001WYK.bed.gz',\n",
    "               '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K4me3/ENCFF001SUM.bed.gz',\n",
    "               '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K27me3/ENCFF001WYB.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K27me3/ENCFF001SUI.bed.gz',\n",
    "              '/Users/rohankrishnamurthi/Downloads/Maalavika_Pillai_Research/Histone Mark Analysis Project/histone_data/GM12878/H3K27me3/ENCFF001WYE.bed.gz']\n",
    "\n",
    "GM1287_list_short = ['GM12878/H3K4me3/ENCFF001WYJ.bed.gz',\n",
    "  'GM12878/H3K4me3/ENCFF001SUF.bed.gz',\n",
    "  'GM12878/H3K4me3/ENCFF001WYK.bed.gz',\n",
    "  'GM12878/H3K4me3/ENCFF001SUM.bed.gz',\n",
    " 'GM12878/H3K4me3/ENCFF001WYB.bed.gz', \n",
    " 'GM12878/H3K4me3/ENCFF001SUI.bed.gz', \n",
    " 'GM12878/H3K4me3/ENCFF001WYE.bed.gz']\n",
    "\n",
    "\n",
    "bed_path = f'{save_folder}/GM12878_bivalency.bed.gz'\n",
    "csv_path = f'{save_folder}/GM12878_bivalency_consensus_all.csv'\n",
    "bed_path = f'{save_folder}/GM12878_bivalency_consensus_all.bed'\n",
    "\n",
    "intersection_list = []\n",
    "for file in GM1287_list:\n",
    "    intersection_list.append(BedTool(file).fn)\n",
    "intersection_list.append(kBP_10_updated.fn)  \n",
    "    \n",
    "result = x.multi_intersect(i=intersection_list)\n",
    "result.saveas(bed_path)\n",
    "\n",
    "len_files = len(GM1287_list_short)\n",
    "n = len_files+5\n",
    "column_mapping = {\n",
    "    0: 'chrom',\n",
    "    1: 'start',\n",
    "    2: 'end',\n",
    "    3: \"peak_count\",\n",
    "    4: \"files\",\n",
    "    n: \"TF_TSS_10kb_named.bed\"\n",
    "}\n",
    "\n",
    "for i in range(0, len_files):\n",
    "    file = GM1287_list_short[i]\n",
    "    column_mapping[i+5] = f\"{file}\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(bed_path, sep='\\t', header=None)\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Ensure peaks are found in all replicate experiments\n",
    "df_filtered = df[df[\"peak_count\"] == max(df[\"peak_count\"])]\n",
    "\n",
    "df_filtered.to_csv(csv_path, index = False)\n",
    "df_filtered.to_csv(bed_path_2, sep='\\t', index=False, header=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
